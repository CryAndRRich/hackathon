import streamlit as st
import os
import requests
from pdf2docx import Converter
from docx import Document
import tempfile
import csv

# Path c·ªßa file CSV l∆∞u l·ªãch s·ª≠ h·ªèi-ƒë√°p
CSV_PATH = "qa_history.csv"
API_KEY = "AIzaSyBJo4sK0hzzeopDSj4GOUzsL6A9DEzTNZ4"
URL_API = (
    f"https://generativelanguage.googleapis.com/v1beta/models/"
    f"gemini-2.0-flash:generateContent?key={API_KEY}"
)

def save_qa_to_csv(question, answer):
    """Append m·ªôt d√≤ng question‚Äìanswer v√†o CSV."""
    with open(CSV_PATH, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([question, answer])

def load_previous_context():
    """N·∫°p 3 c·∫∑p QA g·∫ßn nh·∫•t l√†m ng·ªØ c·∫£nh (n·∫øu c√≥)."""
    if not os.path.exists(CSV_PATH):
        return ""
    with open(CSV_PATH, mode="r", encoding="utf-8") as f:
        reader = csv.reader(f)
        history = list(reader)
        context = ""
        for q, a in history[-3:]:
            context += f"Q: {q}\nA: {a}\n"
        return context

def call_gemini(question: str, content: str):
    """G·ªçi API Gemini, th√™m ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥ v√†o prompt."""
    previous_context = load_previous_context()
    prompt = (
        f"""Use the document content and previous conversation to answer the question.
        ## Document Content:
        {content}

        ## Previous Conversation:
        {previous_context}

        ## Current Question:
        {question}
        """
    )
    headers = {"Content-Type": "application/json"}
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(URL_API, json=payload, headers=headers, timeout=10)
        response.raise_for_status()
        data = response.json().get("candidates", [])
        if not data:
            return "API returned no valid candidates."
        return data[0]["content"]["parts"][0]["text"].strip()
    except Exception as e:
        return f"Error calling Gemini API: {e}"

# Kh·ªüi t·∫°o session_state ƒë·ªÉ l∆∞u chat history v√† n·ªôi dung t√†i li·ªáu
if "messages" not in st.session_state:
    st.session_state["messages"] = []  # m·ªói ph·∫ßn t·ª≠: {"role": "user"/"assistant", "text": str}
if "doc_text" not in st.session_state:
    st.session_state["doc_text"] = ""  # to√†n b·ªô text c·ªßa PDF ƒë√£ chuy·ªÉn

# Sidebar: upload v√† hi·ªÉn th·ªã n·ªôi dung t√≥m t·∫Øt
with st.sidebar:
    st.header("üìÇ T·∫£i l√™n PDF")
    uploaded_file = st.file_uploader("", type=["pdf"])
    if uploaded_file:
        st.success(f"ƒê√£ t·∫£i: {uploaded_file.name}")
        # L∆∞u file PDF t·∫°m
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_pdf:
            tmp_pdf.write(uploaded_file.read())
            pdf_path = tmp_pdf.name
        # ƒê∆∞·ªùng d·∫´n .docx
        docx_path = pdf_path.replace(".pdf", ".docx")
        # Chuy·ªÉn PDF ‚Üí DOCX
        with st.spinner("ƒêang chuy·ªÉn PDF th√†nh DOCX..."):
            cv = Converter(pdf_path)
            cv.convert(docx_path, start=0, end=None)
            cv.close()
        # Tr√≠ch xu·∫•t text t·ª´ DOCX
        with st.spinner("ƒêang tr√≠ch xu·∫•t text t·ª´ DOCX..."):
            doc = Document(docx_path)
            full_text = "\n".join([para.text for para in doc.paragraphs])
        st.session_state["doc_text"] = full_text
        # Hi·ªÉn th·ªã ƒëo·∫°n preview (collapse)
        with st.expander("üìÑ Xem n·ªôi dung tr√≠ch xu·∫•t"):
            st.text_area("Text t·ª´ PDF", full_text, height=300)
        # X√≥a temp files
        os.remove(pdf_path)
        os.remove(docx_path)

st.title("üí¨ Chat Research")

# --- Ph·∫ßn chatbox: messages + input c·ªë ƒë·ªãnh ---
# 2) Hi·ªÉn th·ªã t·∫•t c·∫£ messages trong div v·ª´a t·∫°o
st.markdown('<div class="chat-container">', unsafe_allow_html=True)
for msg in st.session_state["messages"]:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["text"])
    else:
        st.chat_message("assistant").write(msg["text"])
st.markdown("</div>", unsafe_allow_html=True)

# 3) Chat input lu√¥n n·∫±m d∆∞·ªõi div ch·ª©a messages
if st.session_state["doc_text"]:
    user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...")
else:
    user_input = st.chat_input("Vui l√≤ng t·∫£i l√™n PDF tr∆∞·ªõc khi h·ªèi...")

if user_input:
    if not st.session_state["doc_text"]:
        st.warning("B·∫°n h√£y t·∫£i l√™n file PDF ƒë·ªÉ c√≥ t√†i li·ªáu l√†m ng·ªØ c·∫£nh.")
    else:
        # Th√™m tin nh·∫Øn user v√†o session state v√† hi·ªÉn th·ªã lu√¥n
        st.session_state["messages"].append({"role": "user", "text": user_input})
        st.chat_message("user").write(user_input)

        # G·ªçi Gemini ƒë·ªÉ l·∫•y c√¢u tr·∫£ l·ªùi
        with st.spinner("ƒêang t·∫°o ph·∫£n h·ªìi..."):
            answer_text = call_gemini(user_input, st.session_state["doc_text"])

        # Th√™m tin nh·∫Øn assistant v√†o session state v√† hi·ªÉn th·ªã
        st.session_state["messages"].append({"role": "assistant", "text": answer_text})
        st.chat_message("assistant").write(answer_text)

        # L∆∞u QA v√†o CSV
        save_qa_to_csv(user_input, answer_text)
